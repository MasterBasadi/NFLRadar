{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# NFLRadar Pro Football Reference Web Scraping Model\n",
    "## Author: Basit Umair\n",
    "## Description:\n",
    "This script fetches NFL match data from Pro Football Reference using *BeautifulSoup* and modelled with *Pandas* into a dataframe.\n",
    "Used as the data for the NFLRadar prediction module\n",
    "### Inspired by DataQuest tutorial"
   ],
   "id": "c641eadd5a8007d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T03:47:03.050525Z",
     "start_time": "2025-11-13T03:47:01.692895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ],
   "id": "ebc37beb323ed1bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/basitumair/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T03:47:04.328225Z",
     "start_time": "2025-11-13T03:47:04.321014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "column_mapping = {  ## create a mapping of old names to clean names\n",
    "    'unnamed:_0_level_0_week': 'week',\n",
    "    'unnamed:_1_level_0_day': 'day',\n",
    "    'unnamed:_2_level_0_date': 'date',\n",
    "    'unnamed:_3_level_0_unnamed:_3_level_1': 'time',\n",
    "    'unnamed:_4_level_0_unnamed:_4_level_1': 'boxscore_link',\n",
    "    'unnamed:_5_level_0_unnamed:_5_level_1': 'result',\n",
    "    'unnamed:_6_level_0_ot': 'overtime',\n",
    "    'unnamed:_7_level_0_rec': 'record',\n",
    "    'unnamed:_8_level_0_unnamed:_8_level_1': 'home_away',\n",
    "    'unnamed:_9_level_0_opp': 'opponent',\n",
    "    'score_tm': 'team_score',\n",
    "    'score_opp': 'opponent_score',\n",
    "    'offense_1std': 'offense_first_downs',\n",
    "    'offense_totyd': 'offense_total_yards',\n",
    "    'offense_passy': 'offense_passing_yards',\n",
    "    'offense_rushy': 'offense_rushing_yards',\n",
    "    'offense_to': 'offense_turnovers',\n",
    "    'defense_1std': 'defense_first_downs_allowed',\n",
    "    'defense_totyd': 'defense_total_yards_allowed',\n",
    "    'defense_passy': 'defense_passing_yards_allowed',\n",
    "    'defense_rushy': 'defense_rushing_yards_allowed',\n",
    "    'defense_to': 'defense_turnovers_forced',\n",
    "    'expected_points_offense': 'expected_points_offense',\n",
    "    'expected_points_defense': 'expected_points_defense',\n",
    "    'expected_points_sp._tms': 'expected_points_special_teams',\n",
    "    'team': 'team',\n",
    "    'season': 'season'\n",
    "}\n",
    "current_year = int(datetime.now().year)\n",
    "years = list(range(current_year, current_year - 5, -1))  ## 2025, 2024, 2023, 2022, 2021\n",
    "\n",
    "header = { ## be a respectful user\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "        }"
   ],
   "id": "e7bbd2722306205",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T03:47:14.580526Z",
     "start_time": "2025-11-13T03:47:05.996688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_matches = []  ## list that will contain info for all matches\n",
    "for year in years:  ## iterates from the current year down to 5 years ago. Ex. 2025 - 2021\n",
    "    standings_url = f\"https://www.pro-football-reference.com/years/{year}/index.htm\"\n",
    "    header = { ## be a respectful user\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    print(f\"{standings_url}\")\n",
    "\n",
    "    data = requests.get(standings_url, headers=header)  ## getting HTML from the website\n",
    "    soup = BeautifulSoup(data.text, features=\"html.parser\")  ## parsing html\n",
    "    afc_standings_table = soup.select('table.stats_table')[0]  ## get afc & nfc tables\n",
    "    nfc_standings_table = soup.select('table.stats_table')[1]\n",
    "\n",
    "    afc_links = afc_standings_table.find_all('a')  ## looking for anchors in the HTML to help find links\n",
    "    nfc_links = nfc_standings_table.find_all('a')\n",
    "\n",
    "    afc_links = [al.get(\"href\") for al in afc_links]  ## get the hrefs from the anchors to get the urls\n",
    "    afc_links = [al for al in afc_links if '/teams/' in al]  ## filter only for teams\n",
    "\n",
    "    nfc_links = [nl.get(\"href\") for nl in nfc_links]\n",
    "    nfc_links = [nl for nl in nfc_links if '/teams/' in nl]\n",
    "\n",
    "    links = afc_links + nfc_links  ## combine afc and nfc links\n",
    "    teams_urls = [f\"https://www.pro-football-reference.com{l}\" for l in links]  ## specific links for each team\n",
    "    time.sleep(8)  ## delay loop for 8 seconds to prevent being banned from scraping\n",
    "\n",
    "    for team_url in teams_urls:  ## iterate through team urls\n",
    "        team_abbreviation = team_url.split('/')[-2].upper()  ## get team abbreviations Ex. BUF\n",
    "        try:\n",
    "            team_data = requests.get(team_url, headers=header)\n",
    "            matches = pd.read_html(StringIO(team_data.text), match=\"Schedule & Game Results\")\n",
    "            if matches:  # make sure we got some data\n",
    "                team_schedule = matches[0]  # get the first DataFrame\n",
    "                team_schedule['Team'] = team_abbreviation  # add metadata columns\n",
    "                team_schedule['Season'] = year\n",
    "                all_matches.append(team_schedule)  ## append to the main list\n",
    "                print(f\"{team_abbreviation} {year}\")\n",
    "            else:\n",
    "                print(f\"<———NO SCHEDULE DATA FOR {team_abbreviation}———>\")\n",
    "            time.sleep(8)  ## delay loop for 8 seconds to prevent being banned from scraping\n",
    "        except ValueError as e:  ## if there's empty data for either the ongoing season or a Bye Week\n",
    "            print(f\"<———NO SCHEDULE DATA FOR {team_abbreviation}———>\")\n",
    "            continue"
   ],
   "id": "bfe1be9e12eae685",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pro-football-reference.com/years/2025/index.htm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'lxml'.  Use pip or conda to install lxml.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/compat/_optional.py:135\u001B[0m, in \u001B[0;36mimport_optional_dependency\u001B[0;34m(name, extra, errors, min_version)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 135\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:972\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:228\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:984\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'lxml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 31\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     30\u001B[0m     team_data \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(team_url, headers\u001B[38;5;241m=\u001B[39mheader)\n\u001B[0;32m---> 31\u001B[0m     matches \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_html\u001B[49m\u001B[43m(\u001B[49m\u001B[43mStringIO\u001B[49m\u001B[43m(\u001B[49m\u001B[43mteam_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSchedule & Game Results\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m matches:  \u001B[38;5;66;03m# make sure we got some data\u001B[39;00m\n\u001B[1;32m     33\u001B[0m         team_schedule \u001B[38;5;241m=\u001B[39m matches[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# get the first DataFrame\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/html.py:1240\u001B[0m, in \u001B[0;36mread_html\u001B[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001B[0m\n\u001B[1;32m   1224\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(io, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[1;32m   1225\u001B[0m     [\n\u001B[1;32m   1226\u001B[0m         is_file_like(io),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1230\u001B[0m     ]\n\u001B[1;32m   1231\u001B[0m ):\n\u001B[1;32m   1232\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1233\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPassing literal html to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mread_html\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is deprecated and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1234\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwill be removed in a future version. To read from a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1237\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m   1238\u001B[0m     )\n\u001B[0;32m-> 1240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_parse\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1241\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflavor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflavor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[43m    \u001B[49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1243\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1244\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1245\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1246\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskiprows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1247\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1248\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthousands\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthousands\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1249\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1250\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1251\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecimal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecimal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mna_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_default_na\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_default_na\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdisplayed_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisplayed_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_links\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_links\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/html.py:971\u001B[0m, in \u001B[0;36m_parse\u001B[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001B[0m\n\u001B[1;32m    969\u001B[0m retained \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    970\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m flav \u001B[38;5;129;01min\u001B[39;00m flavor:\n\u001B[0;32m--> 971\u001B[0m     parser \u001B[38;5;241m=\u001B[39m \u001B[43m_parser_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mflav\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    972\u001B[0m     p \u001B[38;5;241m=\u001B[39m parser(\n\u001B[1;32m    973\u001B[0m         io,\n\u001B[1;32m    974\u001B[0m         compiled_match,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    979\u001B[0m         storage_options,\n\u001B[1;32m    980\u001B[0m     )\n\u001B[1;32m    982\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/html.py:918\u001B[0m, in \u001B[0;36m_parser_dispatch\u001B[0;34m(flavor)\u001B[0m\n\u001B[1;32m    916\u001B[0m     import_optional_dependency(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbs4\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    917\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 918\u001B[0m     \u001B[43mimport_optional_dependency\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlxml.etree\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _valid_parsers[flavor]\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/compat/_optional.py:138\u001B[0m, in \u001B[0;36mimport_optional_dependency\u001B[0;34m(name, extra, errors, min_version)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 138\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: Missing optional dependency 'lxml'.  Use pip or conda to install lxml."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if all_matches:  ## concatenate the DataFrames\n",
    "    match_df = pd.concat(all_matches, ignore_index=True)  ## format into a dataframe\n",
    "    if isinstance(match_df.columns, pd.MultiIndex):\n",
    "        match_df.columns = ['_'.join(col).strip('_') for col in match_df.columns.values]  # flatten MultiIndex columns by joining the levels\n",
    "    else:\n",
    "        match_df.columns = match_df.columns.astype(str)  ## convert regular columns to strings\n",
    "    match_df.columns = [col.lower().replace(' ', '_').replace('(', '').replace(')', '') for col in match_df.columns]  ## formating columns\n",
    "    match_df = match_df.rename(columns=column_mapping)  ## apply the mapping\n",
    "\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    match_df.to_csv(\"data/2021_2025_matches.csv\", index=False)  ## export to csv file without index column\n",
    "    match_df.head()"
   ],
   "id": "9e5f49f449ee44f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
